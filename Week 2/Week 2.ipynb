{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd5d45f8-7ceb-4310-966e-06618ea6aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_path = \"GoogleNews-vectors-negative300.bin\"\n",
    "model = KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2af943f8-9fd3-4dfe-a9c2-69966aba453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import contractions\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728b63f5-24f4-4a8e-9df9-1e92470684cc",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11119a51-f147-40de-8606-8929ac1d23dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_message_class(model, w2v_model, message):\n",
    "    total = 0\n",
    "    temp = 0\n",
    "    for word in message:\n",
    "        if word in w2v_model.key_to_index:\n",
    "            total += 1\n",
    "            temp += w2v_model[word]\n",
    "    if total > 0:\n",
    "        message = [temp / total]\n",
    "    else:\n",
    "        message = [[0]*300]\n",
    "    prediction = model.predict(message)\n",
    "    return \"ham\" if prediction==1 else \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9eae93f8-19b5-4f92-9295-ced6d81985d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9596412556053812\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "lines = []\n",
    "with open(\"spamhamdata.csv\") as file:\n",
    "    lines = file.readlines()\n",
    "lines\n",
    "labels = []\n",
    "classes = []\n",
    "messages = []\n",
    "vectors = []\n",
    "for line in lines:\n",
    "    label, message = line.split(\"\\t\")\n",
    "    message.replace(\"\\n\", \"\")\n",
    "    labels.append(label)\n",
    "    classes.append(1 if label==\"ham\" else 0)\n",
    "    message = message.lower()\n",
    "    messages.append(message)\n",
    "    message_word = message.split()\n",
    "    result_words  = [word for word in message_word if word not in stop_words]\n",
    "    message = ' '.join(result_words)\n",
    "    vectors.append(WhitespaceTokenizer().tokenize(message))\n",
    "for i in range(len(vectors)):\n",
    "    total = 0\n",
    "    temp = 0\n",
    "    for word in vectors[i]:\n",
    "        if word in model.key_to_index:\n",
    "            total += 1\n",
    "            temp += model[word]\n",
    "    if total != 0:\n",
    "        vectors[i] = temp / total\n",
    "    else:\n",
    "        vectors[i] = [0]*300\n",
    "    X_train, X_test, y_train, y_test = train_test_split(vectors, classes, train_size=0.8, random_state=95)\n",
    "    LR = LogisticRegression()\n",
    "    LR.fit(X_train, y_train)\n",
    "    y_pred = LR.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "# for i in range(len(messages)):\n",
    "#     print(messages[i])\n",
    "#     print(f\"{labels[i]}: \", end=\"\")\n",
    "#     print(predict_message_class(LR, model, messages[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4040d3-da62-4138-ab8c-2d6c39debab7",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "caca5eb7-6c47-4f39-80c3-f402f70f2432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tweet_sentiment(model, w2v_model, tweet):\n",
    "    total = 0\n",
    "    temp = 0\n",
    "    for word in tweets[i].lower().split():\n",
    "        word.replace(\"?\", \"\")\n",
    "        word.replace(\"!\", \"\")\n",
    "        word.replace(\".\", \"\")\n",
    "        word.replace(\",\", \"\")\n",
    "        word.replace(\";\", \"\")\n",
    "        word.replace(\":\", \"\")\n",
    "        word.replace(\"\\\"\", \"\")\n",
    "        word.replace(\"'\", \"\")\n",
    "        if word[0] == \"@\" or \"http\" in word or \"com\" in word or \"//\" in word:\n",
    "            continue\n",
    "        word_expanded = contractions.fix(word)\n",
    "        for new_word in word_expanded:\n",
    "            new_word = lemmatizer.lemmatize(new_word)\n",
    "            if word in w2v_model.key_to_index:\n",
    "                total += 1\n",
    "                temp += w2v_model[word]\n",
    "    if total != 0:\n",
    "        tweet = [temp / total]\n",
    "    else:\n",
    "        tweet = [[0]*300]\n",
    "    prediction = model.predict(tweet)\n",
    "    return \"positive\" if prediction==1 else \"neutral\" if prediction==0 else \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82126606-419f-476a-b877-63a27c81ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "tweets_df = pd.read_csv(\"Tweets.csv\")\n",
    "sentiments = tweets_df[\"airline_sentiment\"]\n",
    "tweets = tweets_df[\"text\"]\n",
    "classes = []\n",
    "vectors = []\n",
    "for i in range(len(tweets)):\n",
    "    temp = 0\n",
    "    total = 0\n",
    "    sentiment = sentiments[i]\n",
    "    for word in tweets[i].lower().split():\n",
    "        word.replace(\"?\", \"\")\n",
    "        word.replace(\"!\", \"\")\n",
    "        word.replace(\".\", \"\")\n",
    "        word.replace(\",\", \"\")\n",
    "        word.replace(\";\", \"\")\n",
    "        word.replace(\":\", \"\")\n",
    "        word.replace(\"\\\"\", \"\")\n",
    "        word.replace(\"'\", \"\")\n",
    "        if word[0] == \"@\" or \"http\" in word or \"com\" in word or \"//\" in word:\n",
    "            continue\n",
    "        word_expanded = contractions.fix(word)\n",
    "        for new_word in word_expanded:\n",
    "            new_word = lemmatizer.lemmatize(new_word)\n",
    "            if word in model.key_to_index:\n",
    "                total += 1\n",
    "                temp += model[word]\n",
    "    if total != 0:\n",
    "        vectors.append(temp / total)\n",
    "    else:\n",
    "        vectors.append([0]*300)\n",
    "    classes.append(1 if sentiment==\"positive\" else 0 if sentiment==\"neutral\" else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a2084d84-dc7a-4073-abcd-5dab29c42544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7745901639344263\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vectors, classes, train_size=0.8, random_state=95)\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "# for i in range(len(tweets)):\n",
    "#     print(tweets[i])\n",
    "#     print(f\"{sentiments[i]}: \", end=\"\")\n",
    "#     print(predict_tweet_sentiment(LR, model, tweets[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gensim-env)",
   "language": "python",
   "name": "gensim-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
